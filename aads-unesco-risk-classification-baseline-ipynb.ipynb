{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:30:51.511581Z","iopub.execute_input":"2025-09-12T21:30:51.511886Z","iopub.status.idle":"2025-09-12T21:30:51.516810Z","shell.execute_reply.started":"2025-09-12T21:30:51.511862Z","shell.execute_reply":"2025-09-12T21:30:51.516021Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AADS_UNESCO_Risk_Classification_Baseline\n\n**Author:** Javed Yasin  \n**Project:** JAVED_UNESCO_AADS_2025 (BLUE_ROBOT)  \n**Goal:** Build a beginner baseline for industrial risk classification to practice AADS research skills.\n\nNotebook structure:\n1. Dataset creation (synthetic)\n2. Exploratory Data Analysis (EDA)\n3. Train Decision Tree & Random Forest\n4. Evaluate and visualize results\n5. Save models and results\n6. Short Abstract/Introduction template for paper practice\n\n**How to use:** Run code cells top-to-bottom. When finished, copy the printed `Classification Report` and the one-paragraph summary you write (below) and paste them into the chat for review.\n","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n# For reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T05:52:29.622731Z","iopub.execute_input":"2025-09-11T05:52:29.623461Z","iopub.status.idle":"2025-09-11T05:52:29.627781Z","shell.execute_reply.started":"2025-09-11T05:52:29.623433Z","shell.execute_reply":"2025-09-11T05:52:29.627068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Imports ===\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n# For reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T05:57:08.511469Z","iopub.execute_input":"2025-09-11T05:57:08.512170Z","iopub.status.idle":"2025-09-11T05:57:08.516678Z","shell.execute_reply.started":"2025-09-11T05:57:08.512142Z","shell.execute_reply":"2025-09-11T05:57:08.516056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 1) Create synthetic sensor dataset ===\nN = 2000\n\ntemperature = np.random.normal(70, 12, N)   # degrees C\nvibration   = np.random.normal(5, 3, N)     # vibration units\nwater_level = np.random.normal(10, 6, N)    # cm\ngas_leak    = np.random.normal(20, 12, N)   # ppm\nintrusion   = np.random.choice([0,1], N, p=[0.92,0.08])  # rare intrusion\n\nlabels = []\nfor i in range(N):\n    if water_level[i] > 25:\n        labels.append(1)   # flood risk\n    elif vibration[i] > 12 or temperature[i] > 110:\n        labels.append(2)   # equipment failure\n    elif intrusion[i] == 1:\n        labels.append(3)   # intrusion\n    else:\n        labels.append(0)   # normal\n\ndf = pd.DataFrame({\n    \"temperature\": temperature,\n    \"vibration\": vibration,\n    \"water_level\": water_level,\n    \"gas_leak\": gas_leak,\n    \"intrusion\": intrusion,\n    \"label\": labels\n})\n\nprint(\"Dataset created. Shape:\", df.shape)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T05:58:05.151546Z","iopub.execute_input":"2025-09-11T05:58:05.152278Z","iopub.status.idle":"2025-09-11T05:58:05.220485Z","shell.execute_reply.started":"2025-09-11T05:58:05.152253Z","shell.execute_reply":"2025-09-11T05:58:05.219765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 2) EDA ===\ndisplay(df.describe().round(2))\n\n# Class distribution\ncounts = df['label'].value_counts().sort_index()\nlabel_names = {0: \"Normal\", 1: \"FloodRisk\", 2: \"EquipFail\", 3: \"Intrusion\"}\nprint(\"\\nClass distribution:\")\nfor k,v in counts.items():\n    print(f\"  {k} ({label_names[k]}): {v} samples\")\n\nplt.figure(figsize=(8,4))\nsns.countplot(x='label', data=df)\nplt.xticks(ticks=[0,1,2,3], labels=[label_names[i] for i in [0,1,2,3]])\nplt.title(\"Class distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T05:58:54.134349Z","iopub.execute_input":"2025-09-11T05:58:54.134691Z","iopub.status.idle":"2025-09-11T05:58:54.621343Z","shell.execute_reply.started":"2025-09-11T05:58:54.134667Z","shell.execute_reply":"2025-09-11T05:58:54.620672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 3) Prepare data ===\nX = df.drop(\"label\", axis=1)\ny = df[\"label\"]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED\n)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled  = scaler.transform(X_test)\n\n# Save dataset to CSV for record\nos.makedirs(\"artifacts\", exist_ok=True)\ndf.to_csv(\"artifacts/synthetic_irm_dataset.csv\", index=False)\nprint(\"Train/test shapes:\", X_train.shape, X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T05:59:52.525177Z","iopub.execute_input":"2025-09-11T05:59:52.525446Z","iopub.status.idle":"2025-09-11T05:59:52.566284Z","shell.execute_reply.started":"2025-09-11T05:59:52.525425Z","shell.execute_reply":"2025-09-11T05:59:52.565534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 4) Decision Tree (baseline) ===\ndt = DecisionTreeClassifier(random_state=RANDOM_SEED, max_depth=6)\ndt.fit(X_train_scaled, y_train)\n\ny_pred_dt = dt.predict(X_test_scaled)\n\nprint(\"Decision Tree - Classification Report:\")\nprint(classification_report(y_test, y_pred_dt, target_names=[label_names[i] for i in [0,1,2,3]]))\n\n# Simple visualization of tree (optional)\nplt.figure(figsize=(12,6))\nplot_tree(dt, feature_names=X.columns, class_names=[label_names[i] for i in [0,1,2,3]], filled=True, fontsize=8)\nplt.title(\"Decision Tree (max_depth=6)\")\nplt.show()\n\n# Save model\njoblib.dump(dt, \"artifacts/decision_tree_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T06:00:25.172645Z","iopub.execute_input":"2025-09-11T06:00:25.173384Z","iopub.status.idle":"2025-09-11T06:00:25.638903Z","shell.execute_reply.started":"2025-09-11T06:00:25.173361Z","shell.execute_reply":"2025-09-11T06:00:25.638148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 5) Random Forest ===\nrf = RandomForestClassifier(n_estimators=150, random_state=RANDOM_SEED)\nrf.fit(X_train_scaled, y_train)\n\ny_pred_rf = rf.predict(X_test_scaled)\n\nprint(\"Random Forest - Classification Report:\")\nprint(classification_report(y_test, y_pred_rf, target_names=[label_names[i] for i in [0,1,2,3]]))\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=[label_names[i] for i in [0,1,2,3]],\n            yticklabels=[label_names[i] for i in [0,1,2,3]])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Random Forest - Confusion Matrix\")\nplt.show()\n\n# Feature importance\nimportances = rf.feature_importances_\nindices = np.argsort(importances)[::-1]\nplt.figure(figsize=(8,4))\nsns.barplot(x=importances[indices], y=X.columns[indices])\nplt.title(\"Random Forest Feature Importance\")\nplt.tight_layout()\nplt.show()\n\n# Save RF model\njoblib.dump(rf, \"artifacts/random_forest_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T06:01:01.201778Z","iopub.execute_input":"2025-09-11T06:01:01.202066Z","iopub.status.idle":"2025-09-11T06:01:01.926784Z","shell.execute_reply.started":"2025-09-11T06:01:01.202043Z","shell.execute_reply":"2025-09-11T06:01:01.926185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 6) Save results summary ===\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\ndef save_model_results(model_name, y_true, y_pred):\n    acc = accuracy_score(y_true, y_pred)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n    return {\"model\": model_name, \"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n\nresults = []\nresults.append(save_model_results(\"DecisionTree\", y_test, y_pred_dt))\nresults.append(save_model_results(\"RandomForest\", y_test, y_pred_rf))\n\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"artifacts/model_comparison_results.csv\", index=False)\ndisplay(results_df.round(4))\nprint(\"Saved model artifacts in ./artifacts/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T06:02:47.908249Z","iopub.execute_input":"2025-09-11T06:02:47.908911Z","iopub.status.idle":"2025-09-11T06:02:47.928853Z","shell.execute_reply.started":"2025-09-11T06:02:47.908876Z","shell.execute_reply":"2025-09-11T06:02:47.928046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Abstract (write 2–4 sentences in English)\nType your short abstract below (I will correct it). Example starter sentence:\n> This notebook presents a baseline implementation of an industrial risk classification module as part of my AADS research. I simulate sensor data, train baseline classifiers (Decision Tree and Random Forest), and evaluate their performance.\n\n## Introduction (write 3–6 sentences in English)\nType your introduction below (I will correct and polish it). Example start:\n> Intelligent Autonomous Decision Systems (AADS) support emergency management by analyzing sensor streams and recommending actions. In this study I build a simple prototype to classify risk levels using simulated data as a first step toward more realistic IDSS experiments.\n","metadata":{}},{"cell_type":"code","source":"import joblib\n\n# Load models from artifacts\ndt_model = joblib.load(\"./artifacts/DecisionTree_model.pkl\")\nrf_model = joblib.load(\"./artifacts/RandomForest_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:51:43.259727Z","iopub.execute_input":"2025-09-11T16:51:43.259945Z","iopub.status.idle":"2025-09-11T16:51:43.437383Z","shell.execute_reply.started":"2025-09-11T16:51:43.259925Z","shell.execute_reply":"2025-09-11T16:51:43.436217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Example dataset (replace with your dataset file)\ndf = pd.read_csv(\"your_dataset.csv\")\n\nX = df.drop(\"label\", axis=1)\ny = df[\"label\"]\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train models\ndt_model = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n\n# Save models\njoblib.dump(dt_model, \"DecisionTree_model.pkl\")\njoblib.dump(rf_model, \"RandomForest_model.pkl\")\n\nprint(\"✅ Models trained and saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:53:13.032178Z","iopub.execute_input":"2025-09-11T16:53:13.032786Z","iopub.status.idle":"2025-09-11T16:53:14.459540Z","shell.execute_reply.started":"2025-09-11T16:53:13.032742Z","shell.execute_reply":"2025-09-11T16:53:14.458691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris  # example dataset\n\n# === Load dataset (Iris dataset) ===\niris = load_iris()\nX = pd.DataFrame(iris.data, columns=iris.feature_names)\ny = iris.target\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train models\ndt_model = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)\n\n# Save models\njoblib.dump(dt_model, \"DecisionTree_model.pkl\")\njoblib.dump(rf_model, \"RandomForest_model.pkl\")\n\nprint(\"✅ Models trained and saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:55:03.275560Z","iopub.execute_input":"2025-09-11T16:55:03.276128Z","iopub.status.idle":"2025-09-11T16:55:03.598996Z","shell.execute_reply.started":"2025-09-11T16:55:03.276104Z","shell.execute_reply":"2025-09-11T16:55:03.598413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load models\ndt_model = joblib.load(\"DecisionTree_model.pkl\")\nrf_model = joblib.load(\"RandomForest_model.pkl\")\n\n# Predictions\ndt_pred = dt_model.predict(X_test)\nrf_pred = rf_model.predict(X_test)\n\n# Reports\nprint(\"=== Decision Tree Report ===\")\nprint(classification_report(y_test, dt_pred))\n\nprint(\"=== Random Forest Report ===\")\nprint(classification_report(y_test, rf_pred))\n\n# Confusion Matrices\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nsns.heatmap(confusion_matrix(y_test, dt_pred), annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Decision Tree Confusion Matrix\")\nsns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt=\"d\", cmap=\"Greens\", ax=axes[1])\naxes[1].set_title(\"Random Forest Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:57:02.285443Z","iopub.execute_input":"2025-09-11T16:57:02.285964Z","iopub.status.idle":"2025-09-11T16:57:03.244273Z","shell.execute_reply.started":"2025-09-11T16:57:02.285941Z","shell.execute_reply":"2025-09-11T16:57:03.243617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Collect metrics\nresults = {\n    \"Model\": [\"DecisionTree\", \"RandomForest\"],\n    \"Accuracy\": [\n        accuracy_score(y_test, dt_pred),\n        accuracy_score(y_test, rf_pred)\n    ],\n    \"Precision\": [\n        precision_score(y_test, dt_pred, average=\"weighted\"),\n        precision_score(y_test, rf_pred, average=\"weighted\")\n    ],\n    \"Recall\": [\n        recall_score(y_test, dt_pred, average=\"weighted\"),\n        recall_score(y_test, rf_pred, average=\"weighted\")\n    ],\n    \"F1 Score\": [\n        f1_score(y_test, dt_pred, average=\"weighted\"),\n        f1_score(y_test, rf_pred, average=\"weighted\")\n    ]\n}\n\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"model_comparison_results.csv\", index=False)\nprint(\"✅ Results saved to model_comparison_results.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:58:15.915701Z","iopub.execute_input":"2025-09-11T16:58:15.916476Z","iopub.status.idle":"2025-09-11T16:58:15.937059Z","shell.execute_reply.started":"2025-09-11T16:58:15.916451Z","shell.execute_reply":"2025-09-11T16:58:15.936504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\nfrom reportlab.lib.styles import getSampleStyleSheet\n\n# Create PDF\ndoc = SimpleDocTemplate(\"Model_Comparison_Report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nflow = []\n\nflow.append(Paragraph(\"Model Comparison Report\", styles['Title']))\nflow.append(Spacer(1, 12))\n\n# Add table\ntable_data = [df_results.columns.to_list()] + df_results.values.tolist()\ntable = Table(table_data)\nflow.append(table)\n\nflow.append(Spacer(1, 24))\nflow.append(Paragraph(\"This report compares Decision Tree and Random Forest models on the Iris dataset.\", styles['Normal']))\n\ndoc.build(flow)\nprint(\"✅ PDF report created: Model_Comparison_Report.pdf\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:58:39.583049Z","iopub.execute_input":"2025-09-11T16:58:39.583861Z","iopub.status.idle":"2025-09-11T16:58:39.605757Z","shell.execute_reply.started":"2025-09-11T16:58:39.583821Z","shell.execute_reply":"2025-09-11T16:58:39.604918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install reportlab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:59:41.212940Z","iopub.execute_input":"2025-09-11T16:59:41.213204Z","iopub.status.idle":"2025-09-11T16:59:48.741300Z","shell.execute_reply.started":"2025-09-11T16:59:41.213185Z","shell.execute_reply":"2025-09-11T16:59:48.740566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\nfrom reportlab.lib.styles import getSampleStyleSheet\n\n# Create PDF\ndoc = SimpleDocTemplate(\"Model_Comparison_Report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nflow = []\n\nflow.append(Paragraph(\"Model Comparison Report\", styles['Title']))\nflow.append(Spacer(1, 12))\n\n# Add table\ntable_data = [df_results.columns.to_list()] + df_results.values.tolist()\ntable = Table(table_data)\nflow.append(table)\n\nflow.append(Spacer(1, 24))\nflow.append(Paragraph(\"This report compares Decision Tree and Random Forest models on the Iris dataset.\", styles['Normal']))\n\ndoc.build(flow)\nprint(\"✅ PDF report created: Model_Comparison_Report.pdf\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:00:10.375697Z","iopub.execute_input":"2025-09-11T17:00:10.376015Z","iopub.status.idle":"2025-09-11T17:00:10.479545Z","shell.execute_reply.started":"2025-09-11T17:00:10.375987Z","shell.execute_reply":"2025-09-11T17:00:10.478788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install python-docx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:00:51.292105Z","iopub.execute_input":"2025-09-11T17:00:51.292814Z","iopub.status.idle":"2025-09-11T17:00:54.688052Z","shell.execute_reply.started":"2025-09-11T17:00:51.292782Z","shell.execute_reply":"2025-09-11T17:00:54.687300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from docx import Document\n\n# Create a new Word document\ndoc = Document()\n\n# Title\ndoc.add_heading(\"Model Comparison Report\", level=1)\n\n# Intro\ndoc.add_paragraph(\n    \"This report compares the performance of Decision Tree and Random Forest models \"\n    \"on the Iris dataset. Metrics such as Accuracy, Precision, Recall, and F1 Score are included.\"\n)\n\n# Add table\ntable = doc.add_table(rows=1, cols=len(df_results.columns))\nhdr_cells = table.rows[0].cells\nfor i, col_name in enumerate(df_results.columns):\n    hdr_cells[i].text = col_name\n\n# Add rows\nfor row in df_results.values:\n    row_cells = table.add_row().cells\n    for i, val in enumerate(row):\n        row_cells[i].text = str(round(val, 4))\n\n# Save file\ndoc.save(\"Model_Comparison_Report.docx\")\nprint(\"✅ Word report created: Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:01:07.970785Z","iopub.execute_input":"2025-09-11T17:01:07.971448Z","iopub.status.idle":"2025-09-11T17:01:08.147980Z","shell.execute_reply.started":"2025-09-11T17:01:07.971409Z","shell.execute_reply":"2025-09-11T17:01:08.147104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from docx import Document\n\n# Create a new Word document\ndoc = Document()\n\n# Title\ndoc.add_heading(\"Model Comparison Report\", level=1)\n\n# Intro\ndoc.add_paragraph(\n    \"This report compares the performance of Decision Tree and Random Forest models \"\n    \"on the Iris dataset. Metrics such as Accuracy, Precision, Recall, and F1 Score are included.\"\n)\n\n# Add table\ntable = doc.add_table(rows=1, cols=len(df_results.columns))\nhdr_cells = table.rows[0].cells\nfor i, col_name in enumerate(df_results.columns):\n    hdr_cells[i].text = col_name\n\n# Add rows\nfor row in df_results.values:\n    row_cells = table.add_row().cells\n    for i, val in enumerate(row):\n        if isinstance(val, (float, int)):  # numbers → round\n            row_cells[i].text = str(round(val, 4))\n        else:  # strings → keep as is\n            row_cells[i].text = str(val)\n\n# Save file\ndoc.save(\"Model_Comparison_Report.docx\")\nprint(\"✅ Word report created: Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:02:02.099917Z","iopub.execute_input":"2025-09-11T17:02:02.100742Z","iopub.status.idle":"2025-09-11T17:02:02.142474Z","shell.execute_reply.started":"2025-09-11T17:02:02.100716Z","shell.execute_reply":"2025-09-11T17:02:02.141867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"doc.save(\"/kaggle/working/Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:19:17.871342Z","iopub.execute_input":"2025-09-11T17:19:17.871917Z","iopub.status.idle":"2025-09-11T17:19:17.890314Z","shell.execute_reply.started":"2025-09-11T17:19:17.871894Z","shell.execute_reply":"2025-09-11T17:19:17.889693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# For Word\nFileLink(\"/kaggle/working/Model_Comparison_Report.docx\")\n\n# For PDF\nFileLink(\"/kaggle/working/Model_Comparison_Report.pdf\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:19:55.201225Z","iopub.execute_input":"2025-09-11T17:19:55.201880Z","iopub.status.idle":"2025-09-11T17:19:55.206894Z","shell.execute_reply.started":"2025-09-11T17:19:55.201854Z","shell.execute_reply":"2025-09-11T17:19:55.206327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\n\n# ✅ Option 1: single file link\nFileLink(\"Model_Comparison_Report.docx\")\n\n# ✅ Option 2: show all downloadable files in /kaggle/working\nFileLinks(\"/kaggle/working\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:20:59.255528Z","iopub.execute_input":"2025-09-11T17:20:59.256124Z","iopub.status.idle":"2025-09-11T17:20:59.261786Z","shell.execute_reply.started":"2025-09-11T17:20:59.256102Z","shell.execute_reply":"2025-09-11T17:20:59.261165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"doc.save(\"/kaggle/working/Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:21:43.318224Z","iopub.execute_input":"2025-09-11T17:21:43.318941Z","iopub.status.idle":"2025-09-11T17:21:43.337257Z","shell.execute_reply.started":"2025-09-11T17:21:43.318915Z","shell.execute_reply":"2025-09-11T17:21:43.336546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\n\n# ✅ Direct link to your Word report\nFileLink(\"/kaggle/working/Model_Comparison_Report.docx\")\n\n# ✅ (Optional) show all files in working directory\nFileLinks(\"/kaggle/working\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:23:41.077372Z","iopub.execute_input":"2025-09-11T17:23:41.077639Z","iopub.status.idle":"2025-09-11T17:23:41.083398Z","shell.execute_reply.started":"2025-09-11T17:23:41.077619Z","shell.execute_reply":"2025-09-11T17:23:41.082773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\n\n# Show download link for Word report\ndisplay(FileLink(\"/kaggle/working/Model_Comparison_Report.docx\"))\n\n# Show download link for PDF report\ndisplay(FileLink(\"/kaggle/working/Model_Comparison_Report.pdf\"))\n\n# Show all files available in working directory\nFileLinks(\"/kaggle/working\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:25:26.458932Z","iopub.execute_input":"2025-09-11T17:25:26.459571Z","iopub.status.idle":"2025-09-11T17:25:26.467734Z","shell.execute_reply.started":"2025-09-11T17:25:26.459518Z","shell.execute_reply":"2025-09-11T17:25:26.467145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load dataset (replace with your actual dataset file)\ndf = pd.read_csv(\"your_dataset.csv\")\n\n# Load Random Forest model\nrf_model = joblib.load(\"RandomForest_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:30:59.102340Z","iopub.status.idle":"2025-09-12T11:30:59.102732Z","shell.execute_reply.started":"2025-09-12T11:30:59.102524Z","shell.execute_reply":"2025-09-12T11:30:59.102541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature importance\nimportances = rf_model.feature_importances_\nfeatures = df.drop(\"label\", axis=1).columns  \n\n# Plot\nplt.figure(figsize=(8,5))\nplt.barh(features, importances, color=\"skyblue\")\nplt.xlabel(\"Importance\")\nplt.title(\"Feature Importance - Random Forest\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:30:59.104177Z","iopub.status.idle":"2025-09-12T11:30:59.104522Z","shell.execute_reply.started":"2025-09-12T11:30:59.104398Z","shell.execute_reply":"2025-09-12T11:30:59.104413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Dummy dataset with 3 features and a binary label\nnp.random.seed(42)\ndf = pd.DataFrame({\n    \"temperature\": np.random.randint(20, 40, 100),\n    \"pressure\": np.random.randint(80, 120, 100),\n    \"vibration\": np.random.randint(1, 10, 100),\n    \"label\": np.random.randint(0, 2, 100)  # target\n})\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:40:20.044016Z","iopub.execute_input":"2025-09-12T11:40:20.044312Z","iopub.status.idle":"2025-09-12T11:40:20.354399Z","shell.execute_reply.started":"2025-09-12T11:40:20.044291Z","shell.execute_reply":"2025-09-12T11:40:20.353694Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport joblib\n\nX = df.drop(\"label\", axis=1)\ny = df[\"label\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Save model\njoblib.dump(rf_model, \"RandomForest_model.pkl\")\nprint(\"✅ Random Forest trained and saved\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:40:47.592257Z","iopub.execute_input":"2025-09-12T11:40:47.593017Z","iopub.status.idle":"2025-09-12T11:40:48.704114Z","shell.execute_reply.started":"2025-09-12T11:40:47.592991Z","shell.execute_reply":"2025-09-12T11:40:48.703448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimportances = rf_model.feature_importances_\nfeatures = X.columns  \n\nplt.figure(figsize=(8,5))\nplt.barh(features, importances, color=\"skyblue\")\nplt.xlabel(\"Importance\")\nplt.title(\"Feature Importance - Random Forest\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:41:08.745514Z","iopub.execute_input":"2025-09-12T11:41:08.746264Z","iopub.status.idle":"2025-09-12T11:41:08.982664Z","shell.execute_reply.started":"2025-09-12T11:41:08.746236Z","shell.execute_reply":"2025-09-12T11:41:08.981876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\n\njoblib.dump(dt_model, \"DecisionTree_model.pkl\")\nprint(\"✅ Decision Tree trained and saved\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:42:27.164136Z","iopub.execute_input":"2025-09-12T11:42:27.164454Z","iopub.status.idle":"2025-09-12T11:42:27.173869Z","shell.execute_reply.started":"2025-09-12T11:42:27.164431Z","shell.execute_reply":"2025-09-12T11:42:27.173129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random Forest\nrf_importances = rf_model.feature_importances_\n\n# Decision Tree\ndt_importances = dt_model.feature_importances_\n\n# Put into DataFrame\nimportance_df = pd.DataFrame({\n    \"Feature\": X.columns,\n    \"DecisionTree\": dt_importances,\n    \"RandomForest\": rf_importances\n})\n\nprint(importance_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:42:44.076696Z","iopub.execute_input":"2025-09-12T11:42:44.076976Z","iopub.status.idle":"2025-09-12T11:42:44.090110Z","shell.execute_reply.started":"2025-09-12T11:42:44.076958Z","shell.execute_reply":"2025-09-12T11:42:44.089182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"importance_df.set_index(\"Feature\").plot(kind=\"bar\", figsize=(8,5))\nplt.title(\"Feature Importance: Decision Tree vs Random Forest\")\nplt.ylabel(\"Importance\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:45:05.095461Z","iopub.execute_input":"2025-09-12T11:45:05.096131Z","iopub.status.idle":"2025-09-12T11:45:05.416043Z","shell.execute_reply.started":"2025-09-12T11:45:05.096105Z","shell.execute_reply":"2025-09-12T11:45:05.415244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install python-docx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:46:36.214793Z","iopub.execute_input":"2025-09-12T11:46:36.215084Z","iopub.status.idle":"2025-09-12T11:46:40.620495Z","shell.execute_reply.started":"2025-09-12T11:46:36.215063Z","shell.execute_reply":"2025-09-12T11:46:40.619435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from docx import Document\nfrom docx.shared import Inches\nimport matplotlib.pyplot as plt\n\n# Create Word document\ndoc = Document()\ndoc.add_heading(\"Model Comparison Report\", 0)\n\n# Section 1: Dataset\ndoc.add_heading(\"1. Dataset\", level=1)\ndoc.add_paragraph(\"The dataset was used for classification with input features (X) and target label (y). \"\n                  \"Data was split into training and test sets using 80/20 ratio.\")\n\n# Section 2: Model Performance\ndoc.add_heading(\"2. Model Performance\", level=1)\ndoc.add_paragraph(\"The following table shows the performance metrics for Decision Tree and Random Forest models:\")\n\n# Add table with results from your first task\nresults = [\n    [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"],\n    [\"DecisionTree\", \"1.0000\", \"1.0000\", \"1.0000\", \"1.0000\"],\n    [\"RandomForest\", \"0.9975\", \"0.9976\", \"0.9975\", \"0.9973\"]\n]\ntable = doc.add_table(rows=1, cols=len(results[0]))\ntable.style = 'LightShading-Accent1'\n\n# Header row\nhdr_cells = table.rows[0].cells\nfor i, val in enumerate(results[0]):\n    hdr_cells[i].text = val\n\n# Data rows\nfor row in results[1:]:\n    row_cells = table.add_row().cells\n    for i, val in enumerate(row):\n        row_cells[i].text = val\n\n# Section 3: Feature Importance\ndoc.add_heading(\"3. Feature Importance Comparison\", level=1)\ndoc.add_paragraph(\"We compared the feature importance scores of Decision Tree and Random Forest. \"\n                  \"The chart below shows their differences:\")\n\n# Plot and save feature importance chart\nimportance_df.set_index(\"Feature\").plot(kind=\"bar\", figsize=(8,5))\nplt.title(\"Feature Importance: Decision Tree vs Random Forest\")\nplt.ylabel(\"Importance\")\nplt.tight_layout()\nplt.savefig(\"feature_importance.png\")\nplt.close()\n\n# Add chart image to Word\ndoc.add_picture(\"feature_importance.png\", width=Inches(5))\n\n# Section 4: Conclusion\ndoc.add_heading(\"4. Conclusion\", level=1)\ndoc.add_paragraph(\n    \"The Decision Tree achieved perfect training performance, but Random Forest provided more stable feature importance values. \"\n    \"Random Forest is generally preferred for research as it reduces overfitting and provides more reliable feature ranking.\"\n)\n\n# Save Word report\ndoc.save(\"/kaggle/working/Model_Comparison_Report.docx\")\nprint(\"✅ Word report created: Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:47:13.657483Z","iopub.execute_input":"2025-09-12T11:47:13.658123Z","iopub.status.idle":"2025-09-12T11:47:14.000431Z","shell.execute_reply.started":"2025-09-12T11:47:13.658090Z","shell.execute_reply":"2025-09-12T11:47:13.999554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"/kaggle/working/Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:47:37.290225Z","iopub.execute_input":"2025-09-12T11:47:37.291299Z","iopub.status.idle":"2025-09-12T11:47:37.296934Z","shell.execute_reply.started":"2025-09-12T11:47:37.291266Z","shell.execute_reply":"2025-09-12T11:47:37.296275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"doc.save(\"/kaggle/working/Model_Comparison_Report.docx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:48:39.072689Z","iopub.execute_input":"2025-09-12T11:48:39.073001Z","iopub.status.idle":"2025-09-12T11:48:39.094822Z","shell.execute_reply.started":"2025-09-12T11:48:39.072981Z","shell.execute_reply":"2025-09-12T11:48:39.094178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Model_Comparison_Report.docx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:49:07.579160Z","iopub.execute_input":"2025-09-12T11:49:07.579453Z","iopub.status.idle":"2025-09-12T11:49:07.662039Z","shell.execute_reply.started":"2025-09-12T11:49:07.579429Z","shell.execute_reply":"2025-09-12T11:49:07.661028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# 1) Define Neural Net\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# 2) Prepare Data\nX = df.drop(\"label\", axis=1).values\ny = df[\"label\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train_torch = torch.tensor(X_train, dtype=torch.float32)\ny_train_torch = torch.tensor(y_train, dtype=torch.long)\nX_test_torch = torch.tensor(X_test, dtype=torch.float32)\ny_test_torch = torch.tensor(y_test, dtype=torch.long)\n\n# 3) Train Neural Net\nmodel = SimpleNN(input_dim=X_train.shape[1], hidden_dim=64, output_dim=len(set(y)))\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nfor epoch in range(20):  # small epochs for practice\n    optimizer.zero_grad()\n    outputs = model(X_train_torch)\n    loss = criterion(outputs, y_train_torch)\n    loss.backward()\n    optimizer.step()\n\n# 4) Evaluate\nwith torch.no_grad():\n    preds = model(X_test_torch).argmax(axis=1).numpy()\n\nacc = accuracy_score(y_test, preds)\nprec = precision_score(y_test, preds, average=\"weighted\")\nrec = recall_score(y_test, preds, average=\"weighted\")\nf1 = f1_score(y_test, preds, average=\"weighted\")\n\nprint(\"Neural Network Results:\", acc, prec, rec, f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T11:53:08.118174Z","iopub.execute_input":"2025-09-12T11:53:08.118484Z","iopub.status.idle":"2025-09-12T11:53:14.648881Z","shell.execute_reply.started":"2025-09-12T11:53:08.118457Z","shell.execute_reply":"2025-09-12T11:53:14.647962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 1) Imports ===\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# === 2) Load Dataset ===\ndf = pd.read_csv(\"/kaggle/input/your_dataset.csv\")  # change filename if needed\n\nX = df.drop(\"label\", axis=1).values\ny = df[\"label\"].values\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# === 3) Feature Scaling ===\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# === 4) Baseline Models ===\ndt = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42)\n\ndt.fit(X_train, y_train)\nrf.fit(X_train, y_train)\n\n# Evaluate baseline\ndt_preds = dt.predict(X_test)\nrf_preds = rf.predict(X_test)\n\nprint(\"Decision Tree:\", \n      accuracy_score(y_test, dt_preds), \n      precision_score(y_test, dt_preds, average='macro'),\n      recall_score(y_test, dt_preds, average='macro'),\n      f1_score(y_test, dt_preds, average='macro'))\n\nprint(\"Random Forest:\", \n      accuracy_score(y_test, rf_preds), \n      precision_score(y_test, rf_preds, average='macro'),\n      recall_score(y_test, rf_preds, average='macro'),\n      f1_score(y_test, rf_preds, average='macro'))\n\n# === 5) Neural Network ===\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, len(np.unique(y)))  # output = num classes\n        )\n    def forward(self, x):\n        return self.layers(x)\n\n# Model, Loss, Optimizer\ninput_dim = X_train_scaled.shape[1]\nmodel = SimpleNN(input_dim)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Convert to torch tensors\nX_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_torch = torch.tensor(y_train, dtype=torch.long)\nX_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_torch = torch.tensor(y_test, dtype=torch.long)\n\n# Training loop\nfor epoch in range(100):  # 100 epochs\n    optimizer.zero_grad()\n    outputs = model(X_train_torch)\n    loss = criterion(outputs, y_train_torch)\n    loss.backward()\n    optimizer.step()\n    if (epoch+1) % 20 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n# Evaluation\nwith torch.no_grad():\n    outputs = model(X_test_torch)\n    _, preds = torch.max(outputs, 1)\n\nnn_acc = accuracy_score(y_test, preds)\nnn_prec = precision_score(y_test, preds, average='macro', zero_division=0)\nnn_rec = recall_score(y_test, preds, average='macro', zero_division=0)\nnn_f1 = f1_score(y_test, preds, average='macro', zero_division=0)\n\nprint(\"Ne\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:12:37.245999Z","iopub.execute_input":"2025-09-12T21:12:37.246244Z","iopub.status.idle":"2025-09-12T21:12:37.264387Z","shell.execute_reply.started":"2025-09-12T21:12:37.246198Z","shell.execute_reply":"2025-09-12T21:12:37.263279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation\nwith torch.no_grad():\n    outputs = model(X_test_torch)\n    _, preds = torch.max(outputs, 1)\n\nnn_acc = accuracy_score(y_test, preds)\nnn_prec = precision_score(y_test, preds, average='macro', zero_division=0)\nnn_rec = recall_score(y_test, preds, average='macro', zero_division=0)\nnn_f1 = f1_score(y_test, preds, average='macro', zero_division=0)\n\nprint(\"Neural Network:\", nn_acc, nn_prec, nn_rec, nn_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:16:57.954950Z","iopub.execute_input":"2025-09-12T21:16:57.955252Z","iopub.status.idle":"2025-09-12T21:16:57.965522Z","shell.execute_reply.started":"2025-09-12T21:16:57.955199Z","shell.execute_reply":"2025-09-12T21:16:57.964745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:16:40.388879Z","iopub.execute_input":"2025-09-12T21:16:40.389168Z","iopub.status.idle":"2025-09-12T21:16:44.561556Z","shell.execute_reply.started":"2025-09-12T21:16:40.389145Z","shell.execute_reply":"2025-09-12T21:16:44.560967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:17:16.305050Z","iopub.execute_input":"2025-09-12T21:17:16.305350Z","iopub.status.idle":"2025-09-12T21:17:16.308758Z","shell.execute_reply.started":"2025-09-12T21:17:16.305326Z","shell.execute_reply":"2025-09-12T21:17:16.308106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === 1) Imports ===\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# === 2) Load Dataset ===\ndf = pd.read_csv(\"/kaggle/input/your_dataset.csv\")  # change filename if needed\n\nX = df.drop(\"label\", axis=1).values\ny = df[\"label\"].values\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# === 3) Feature Scaling ===\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# === 4) Baseline Models ===\ndt = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42)\n\ndt.fit(X_train, y_train)\nrf.fit(X_train, y_train)\n\n# Evaluate baseline\ndt_preds = dt.predict(X_test)\nrf_preds = rf.predict(X_test)\n\nprint(\"Decision Tree:\", \n      accuracy_score(y_test, dt_preds), \n      precision_score(y_test, dt_preds, average='macro'),\n      recall_score(y_test, dt_preds, average='macro'),\n      f1_score(y_test, dt_preds, average='macro'))\n\nprint(\"Random Forest:\", \n      accuracy_score(y_test, rf_preds), \n      precision_score(y_test, rf_preds, average='macro'),\n      recall_score(y_test, rf_preds, average='macro'),\n      f1_score(y_test, rf_preds, average='macro'))\n\n# === 5) Neural Network ===\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, len(np.unique(y)))  # output = num classes\n        )\n    def forward(self, x):\n        return self.layers(x)\n\n# Model, Loss, Optimizer\ninput_dim = X_train_scaled.shape[1]\nmodel = SimpleNN(input_dim)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Convert to torch tensors\nX_train_torch = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_torch = torch.tensor(y_train, dtype=torch.long)\nX_test_torch = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_torch = torch.tensor(y_test, dtype=torch.long)\n\n# Training loop\nfor epoch in range(100):  # 100 epochs\n    optimizer.zero_grad()\n    outputs = model(X_train_torch)\n    loss = criterion(outputs, y_train_torch)\n    loss.backward()\n    optimizer.step()\n    if (epoch+1) % 20 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\n# Evaluation\nwith torch.no_grad():\n    outputs = model(X_test_torch)\n    _, preds = torch.max(outputs, 1)\n\nnn_acc = accuracy_score(y_test, preds)\nnn_prec = precision_score(y_test, preds, average='macro', zero_division=0)\nnn_rec = recall_score(y_test, preds, average='macro', zero_division=0)\nnn_f1 = f1_score(y_test, preds, average='macro', zero_division=0)\n\nprint(\"Neural Network:\", nn_acc, nn_prec, nn_rec, nn_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:17:56.109135Z","iopub.execute_input":"2025-09-12T21:17:56.109899Z","iopub.status.idle":"2025-09-12T21:17:57.357868Z","shell.execute_reply.started":"2025-09-12T21:17:56.109874Z","shell.execute_reply":"2025-09-12T21:17:57.356882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/iris/Iris.csv\")\n\n# Features (X) and target (y)\nX = df.drop([\"Id\", \"Species\"], axis=1).values\ny = LabelEncoder().fit_transform(df[\"Species\"])  # Convert labels to 0,1,2\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:51:28.273488Z","iopub.execute_input":"2025-09-12T21:51:28.273772Z","iopub.status.idle":"2025-09-12T21:51:28.283010Z","shell.execute_reply.started":"2025-09-12T21:51:28.273752Z","shell.execute_reply":"2025-09-12T21:51:28.282444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Convert to tensors\nX_train_torch = torch.tensor(X_train, dtype=torch.float32)\ny_train_torch = torch.tensor(y_train, dtype=torch.long)\nX_test_torch = torch.tensor(X_test, dtype=torch.float32)\ny_test_torch = torch.tensor(y_test, dtype=torch.long)\n\n# Define NN\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(4, 16)   # input = 4 features\n        self.fc2 = nn.Linear(16, 8)\n        self.fc3 = nn.Linear(8, 3)    # output = 3 classes\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# Initialize\nmodel = SimpleNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:51:56.074404Z","iopub.execute_input":"2025-09-12T21:51:56.074657Z","iopub.status.idle":"2025-09-12T21:51:59.143750Z","shell.execute_reply.started":"2025-09-12T21:51:56.074639Z","shell.execute_reply":"2025-09-12T21:51:59.142962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nepochs = 50\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(X_train_torch)\n    loss = criterion(outputs, y_train_torch)\n    loss.backward()\n    optimizer.step()\n\n    if (epoch+1) % 10 == 0:\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:52:13.672797Z","iopub.execute_input":"2025-09-12T21:52:13.673472Z","iopub.status.idle":"2025-09-12T21:52:13.964844Z","shell.execute_reply.started":"2025-09-12T21:52:13.673447Z","shell.execute_reply":"2025-09-12T21:52:13.964124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Predictions\nwith torch.no_grad():\n    y_pred = model(X_test_torch)\n    _, preds = torch.max(y_pred, 1)\n\n# Evaluation\nprint(\"Accuracy:\", accuracy_score(y_test, preds))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, preds, target_names=df[\"Species\"].unique()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T21:52:41.446500Z","iopub.execute_input":"2025-09-12T21:52:41.447039Z","iopub.status.idle":"2025-09-12T21:52:41.466713Z","shell.execute_reply.started":"2025-09-12T21:52:41.447017Z","shell.execute_reply":"2025-09-12T21:52:41.465931Z"}},"outputs":[],"execution_count":null}]}